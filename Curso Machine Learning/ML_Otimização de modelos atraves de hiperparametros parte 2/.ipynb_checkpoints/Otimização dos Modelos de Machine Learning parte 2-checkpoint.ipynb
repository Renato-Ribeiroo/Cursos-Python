{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f99d23",
   "metadata": {},
   "source": [
    "## Otimização dos nossos Modelos\n",
    "\n",
    "### Dois conceitos que sabemos, Machine Learning Classificação e Validação Cruzada que utlizaremos nesse curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8ad3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Invalid requirement: 'graphviz-==0.9'\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\renato\\anaconda3\\lib\\site-packages (1.4.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\renato\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\renato\\anaconda3\\lib\\site-packages (from pydot) (3.0.4)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz-==0.9\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8291716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preco</th>\n",
       "      <th>vendido</th>\n",
       "      <th>idade_do_modelo</th>\n",
       "      <th>km_por_ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30941.02</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>35085.22134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40557.96</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12622.05362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89627.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11440.79806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95276.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43167.32682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117384.68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12770.11290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preco  vendido  idade_do_modelo   km_por_ano\n",
       "0   30941.02        1               18  35085.22134\n",
       "1   40557.96        1               20  12622.05362\n",
       "2   89627.50        0               12  11440.79806\n",
       "3   95276.14        0                3  43167.32682\n",
       "4  117384.68        1                4  12770.11290"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
    "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64bd6ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preco</th>\n",
       "      <th>vendido</th>\n",
       "      <th>idade_do_modelo</th>\n",
       "      <th>km_por_ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>74023.29</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>24812.80412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>84843.49</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>23095.63834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>83100.27</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>36240.72746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>87932.13</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>32249.56426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>77937.01</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>28414.50704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         preco  vendido  idade_do_modelo   km_por_ano\n",
       "4999  74023.29        0               12  24812.80412\n",
       "5322  84843.49        0               13  23095.63834\n",
       "5319  83100.27        0               19  36240.72746\n",
       "5316  87932.13        0               16  32249.56426\n",
       "5315  77937.01        0               15  28414.50704"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
    "dados_azar = dados.sort_values(\"vendido\", ascending=True)\n",
    "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\",\"km_por_ano\"]]\n",
    "y_azar = dados_azar[\"vendido\"]\n",
    "dados_azar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86051da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy com dummy stratified, 10 = [58.00, 58.00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DummyClassifier()\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f269ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy com cross validation, 10 = [73.83, 77.73]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print(\"Accuracy com cross validation, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8803eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preco</th>\n",
       "      <th>vendido</th>\n",
       "      <th>idade_do_modelo</th>\n",
       "      <th>km_por_ano</th>\n",
       "      <th>modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30941.02</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>35085.22134</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40557.96</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12622.05362</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89627.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11440.79806</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95276.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43167.32682</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117384.68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12770.11290</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preco  vendido  idade_do_modelo   km_por_ano  modelo\n",
       "0   30941.02        1               18  35085.22134      18\n",
       "1   40557.96        1               20  12622.05362      24\n",
       "2   89627.50        0               12  11440.79806      14\n",
       "3   95276.14        0                3  43167.32682       6\n",
       "4  117384.68        1                4  12770.11290       5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gerando dados elatorios de modelo de carro para simulacao de agrupamento ao usar nosso estimador\n",
    "\n",
    "np.random.seed(SEED)\n",
    "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
    "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fc26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_resultados(results):\n",
    "  media = results['test_score'].mean() * 100\n",
    "  desvio = results['test_score'].std() * 100\n",
    "  print(\"Accuracy médio %.2f\" % media)\n",
    "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd420157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy médio 75.78\n",
      "Intervalo [73.67, 77.90]\n"
     ]
    }
   ],
   "source": [
    "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupKFold em um pipeline com StandardScaler e SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "modelo = SVC()\n",
    "\n",
    "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f028f4d",
   "metadata": {},
   "source": [
    "## Todos algorítimos acima foram utilizados no curso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Próximo passo utilizar o algoritimo DecisionTreeClassifier.\n",
    "\n",
    "### Pegaremos a variável modelo e iremos imprimir a árvore que foi treinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bdd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54316987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas e plotando a arvore de decisão\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz \n",
    "\n",
    "#treinando para valer. Unico modelos com todos os dados.\n",
    "modelo.fit(x_azar, y_azar)\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
    "                           class_names=[\"não\", \"sim\"],\n",
    "                           feature_names = features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profundidade alterada para 3\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=3)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora temos uma árvore com 3 níveis de decisões a serem tomadas \n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz \n",
    "\n",
    "#treinando para valer. Unico modelos com todos os dados.\n",
    "modelo.fit(x_azar, y_azar)\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
    "                           class_names=[\"não\", \"sim\"],\n",
    "                           feature_names = features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profundidade alterada para 10\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=10)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d032058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora temos uma árvore com 10 níveis de decisões a serem tomadas \n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz \n",
    "\n",
    "#treinando para valer. Unico modelos com todos os dados.\n",
    "modelo.fit(x_azar, y_azar)\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
    "                           class_names=[\"não\", \"sim\"],\n",
    "                           feature_names = features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a259d",
   "metadata": {},
   "source": [
    "### Tendo uma profundidade muito extensa não garante precisão, podemos notar que 3 níveis de decisão é melhor do que 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23fbe6b",
   "metadata": {},
   "source": [
    "# Todos modelos possuem parâmetros, como escolher eles para otimizar o nosso estimador/algorítmo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando os parâmetros, criando um for para testar vários parâmetros de profundidade, 32 decisões para tomar.\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def roda_arvove_de_decisao(max_depth):\n",
    "    SEED = 301\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    cv = GroupKFold(n_splits = 10)\n",
    "    modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "    print (\"Arvore max_depth = %d, media = %.2f\" % (max_depth, results['test_score'].mean() *100))\n",
    "\n",
    "    \n",
    "for i in range(1,33):\n",
    "    roda_arvove_de_decisao(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando os parâmetros, criando um for para testar vários parâmetros de profundidade, 32 decisões para tomar.\n",
    "# imprimindo os dados de treino e teste\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def roda_arvove_de_decisao(max_depth):\n",
    "    SEED = 301\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    cv = GroupKFold(n_splits = 10)\n",
    "    modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "    print (\"Arvore max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth, results['train_score'].mean() *100, results['test_score'].mean() *100))\n",
    "\n",
    "    \n",
    "for i in range(1,33):\n",
    "    roda_arvove_de_decisao(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8a26b",
   "metadata": {},
   "source": [
    "## Concluimos que para os dados de treino a árvore fica cada vez melhor a cada profundidade de decisão, mas para os dados de teste, tanta profundidade fica cada vez pior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jogando os resultados em uma tabela\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def roda_arvove_de_decisao(max_depth):\n",
    "    SEED = 301\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    cv = GroupKFold(n_splits = 10)\n",
    "    modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "    train_score = results['train_score'].mean() *100\n",
    "    test_score = results['test_score'].mean() *100\n",
    "    print (\"Arvore max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth, train_score, test_score))\n",
    "    tabela = [max_depth, train_score, test_score]\n",
    "    return tabela\n",
    "    \n",
    "resutados = [roda_arvove_de_decisao(i) for i in range(1,33)]\n",
    "resutados = pd.DataFrame(resutados, columns=[\"max_depth\", \"train\", \"test\"])\n",
    "resutados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03557d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabalhando a tabela de resultados, plotando as em gráfico\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(x = \"max_depth\", y = \"train\", data= resutados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56800126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotando os dados no mesmo gráfico\n",
    "sns.lineplot(x = \"max_depth\", y = \"train\", data= resutados)\n",
    "sns.lineplot(x = \"max_depth\", y = \"test\", data= resutados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec6eda",
   "metadata": {},
   "source": [
    "## O treino ficou tão bom que o ocorreu OVERFIT, ou seja, exato demais, quase perfeito.\n",
    "\n",
    "## Quase perfeito para os dados de treino significa que, não necessariamente ficará bom para os dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b4689",
   "metadata": {},
   "source": [
    "# OVERFIT : ficou \"perfeito\" para o treino, mas ruim para o teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fda90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as legendas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.lineplot(x = \"max_depth\", y = \"train\", data= resutados)\n",
    "sns.lineplot(x = \"max_depth\", y = \"test\", data= resutados)\n",
    "plt.legend([\"Treino\", \"Teste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenando os melhores resultados para teste\n",
    "resutados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def52a79",
   "metadata": {},
   "source": [
    "# Explorando hiper parâmetros "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceeb80d",
   "metadata": {},
   "source": [
    "## Exploraremos a combinação de 2 hiper parêmetros, max_depth e min_samples_leaf\n",
    "\n",
    "#### min_samples_leaf, que é número mínimo de elementos (samples) em uma folha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e673293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizando a comparação de hiper parâmetro, precisamos encontrar o melhor conjunto que vai otimizar o nosso estimador.\n",
    "def roda_arvore_de_decisao(max_depth, min_samples_leaf):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  cv = GroupKFold(n_splits = 10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "  print(\"Arvore max_depth = %d, min_samples_leaf = %d, treino = %.2f, teste = %.2f\" % (max_depth, min_samples_leaf, train_score, test_score))\n",
    "  tabela = [max_depth, min_samples_leaf, train_score, test_score]\n",
    "  return tabela\n",
    "\n",
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [32, 64, 128, 256]:\n",
    "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
    "      resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprimindo os 5 melhores\n",
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a7f61",
   "metadata": {},
   "source": [
    "## Diversos valores não foram testados, pois testar todas combinações consome muito processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos a correlação entre os parãmentros, para tentar analisar se dentro dos testes existe um grupo de hiper parâmetro é melhor.\n",
    "# Não é 100%, pois não testamos todos os conjutos devido alto consumo de processamento\n",
    "\n",
    "corr = resultados.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotando no gráfico, mapa de calor\n",
    "\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1148449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando os 4 valores através do pandas\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "pd.plotting.scatter_matrix(resultados, figsize = (14, 8), alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdbfb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotando no seaborn\n",
    "\n",
    "sns.pairplot(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotagem abaixo é a correlação entre os dados, grafico muito bonito no seaborn\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos verificar que o min_samples_leaf tem uma correlação com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testaremos outras faixas de valores para o min_samples_leaf.\n",
    "#começamos a explorar os valores. Testamos pedaços do grid e vamos aprofundando tentando encontrar os melhores valores/combinações\n",
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [128, 192, 256, 512]:\n",
    "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
    "      resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = resultados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e00922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encontrando os 5 melhores\n",
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee321c6",
   "metadata": {},
   "source": [
    "# Conclusão : Correlação é uma maneira de tentarmos encontrar os valores que mais otimizam o nosso estimador, com o menor índice de erro e o maior nível de qualidade.\n",
    "\n",
    "## Procuramos as melhores correlações ao invés de gastar muito processamento até encontrar a melhor combinação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98307076",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deef98",
   "metadata": {},
   "source": [
    "# Utilizaremos um terceiro hiper parâmetro do DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split ajusta os parâmetros de descisão nos \"NÓS\" da arvóre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando 3 dimensões de hiper parâmetros\n",
    "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  cv = GroupKFold(n_splits = 10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "  fit_time = results['fit_time'].mean()\n",
    "  score_time = results['score_time'].mean()\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "\n",
    "  tabela = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score, fit_time, score_time]\n",
    "  return tabela\n",
    "\n",
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [32, 64, 128, 256]:\n",
    "        for min_samples_split in [32, 64, 128, 256]:\n",
    "          tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split)\n",
    "          resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\", \"min_samples_split\", \"train\",\"test\", \"fit_time\", \"score_time\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = resultados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c18bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encontrando os 5 melhores\n",
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b2bb7",
   "metadata": {},
   "source": [
    "# Temos um algoritmo muito morozo para realizar diversas combinações, porém explorando o máximo dos hiperparâmetro conseguimos extrair o que há de melhor do nosso algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8ba86",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8d7f6",
   "metadata": {},
   "source": [
    "# O próprio SKLearn possui o GridSearchCV (grid search cross validation), que faz justamente essa busca de hiperparâmetros com validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando espaço de hiper parâmetros com GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# montando a lista de parâmetros para repassar ao GridSearchCV, 4 hiper parâmetros\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "# instanciando a função, passando os parâmetros e atribuindo a uma variável\n",
    "busca = GridSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    cv = GroupKFold(n_splits = 10))\n",
    "# treinando o grid com os dados\n",
    "busca.fit(x_azar, y_azar,groups = dados.modelo)\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os melhores parãmetros\n",
    "busca.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faae51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melhor pontuação\n",
    "busca.best_score_ * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melhor estimador\n",
    "melhor = busca.best_estimator_\n",
    "melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilzando o melhor modelo na base de dados x_azar\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "predicoes = melhor.predict(x_azar) \n",
    "accuracy = accuracy_score(predicoes, y_azar) * 100\n",
    "\n",
    "print(\"Accuracy para os dados foi %.2f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75467cd",
   "metadata": {},
   "source": [
    "### Utilizamos o GridSearchCV do SKLearn para encontrarmos o melhor conjunto de hiperparâmetros em um espaço definido, de modo a otimizar a nossa métrica (accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843cdd9",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8cc56",
   "metadata": {},
   "source": [
    "# Como ter uma estimativa sem o vício nos dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75314023",
   "metadata": {},
   "source": [
    "### Evitaremos a última abordagem pois utilizamos o predict uma unica vez, sendo que estamos utilizando o Cross validation.\n",
    "\n",
    "### No caso de Cross Validation com busca de Hiper parâmetros, fazemos uma nova validação cruzada. Chama-se NESTED Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos o cross validation para a busca inteira e teremos vários scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(busca, x_azar, y_azar, cv = GroupKFold(n_splits=10), groups = dados.modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd279b",
   "metadata": {},
   "source": [
    "# Infelizmente como o pandas não suporte nested validation com group K fold não conseguimos prever o resultado para novos grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9646efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos o K fold normal sem grupos\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "busca = GridSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True))\n",
    "\n",
    "busca.fit(x_azar, y_azar)\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos o cross validation para a busca inteira e teremos vários scores para o kfold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb065778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimindo os resultados\n",
    "def imprime_score(scores):\n",
    "  media = scores.mean() * 100\n",
    "  desvio = scores.std() * 100\n",
    "  print(\"Accuracy médio %.2f\" % media)\n",
    "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprime_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melhor estimador\n",
    "melhor = busca.best_estimator_\n",
    "print(melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4897654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimindo a árvore de decisão com os melhores parâmetros\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True,\n",
    "                          class_names=[\"não\",\"sim\"],\n",
    "                          feature_names=features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cda47",
   "metadata": {},
   "source": [
    "# Temos 3 linhas de decisões a serem tomadas/comparações a serem feitas max_depth.\n",
    "\n",
    "# Mínimo de 32 samples cada, leaf e split. \n",
    "\n",
    "# As decisões de quebras seguem o critério de gini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48968157",
   "metadata": {},
   "source": [
    "### Esse é o melhor modelo real que utilizamos para explorar os hiperparâmetros. Esse tipo de exploração com grid, no qual cada espaço é analisado separadamente, é válido e funciona. Porém, é um processo demorado, e existem otimizações que podem ser feitas para contornar isso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTIMIZAÇÃO DE MODELO PARTE 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
